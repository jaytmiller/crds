<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="Docutils 0.14: http://docutils.sourceforge.net/" />
<title>&lt;string&gt;</title>
<style type="text/css">

/*
:Author: David Goodger (goodger@python.org)
:Id: $Id: html4css1.css 7952 2016-07-26 18:15:59Z milde $
:Copyright: This stylesheet has been placed in the public domain.

Default cascading style sheet for the HTML output of Docutils.

See http://docutils.sf.net/docs/howto/html-stylesheets.html for how to
customize this style sheet.
*/

/* used to remove borders from tables and images */
.borderless, table.borderless td, table.borderless th {
  border: 0 }

table.borderless td, table.borderless th {
  /* Override padding for "table.docutils td" with "! important".
     The right padding separates the table cells. */
  padding: 0 0.5em 0 0 ! important }

.first {
  /* Override more specific margin styles with "! important". */
  margin-top: 0 ! important }

.last, .with-subtitle {
  margin-bottom: 0 ! important }

.hidden {
  display: none }

.subscript {
  vertical-align: sub;
  font-size: smaller }

.superscript {
  vertical-align: super;
  font-size: smaller }

a.toc-backref {
  text-decoration: none ;
  color: black }

blockquote.epigraph {
  margin: 2em 5em ; }

dl.docutils dd {
  margin-bottom: 0.5em }

object[type="image/svg+xml"], object[type="application/x-shockwave-flash"] {
  overflow: hidden;
}

/* Uncomment (and remove this text!) to get bold-faced definition list terms
dl.docutils dt {
  font-weight: bold }
*/

div.abstract {
  margin: 2em 5em }

div.abstract p.topic-title {
  font-weight: bold ;
  text-align: center }

div.admonition, div.attention, div.caution, div.danger, div.error,
div.hint, div.important, div.note, div.tip, div.warning {
  margin: 2em ;
  border: medium outset ;
  padding: 1em }

div.admonition p.admonition-title, div.hint p.admonition-title,
div.important p.admonition-title, div.note p.admonition-title,
div.tip p.admonition-title {
  font-weight: bold ;
  font-family: sans-serif }

div.attention p.admonition-title, div.caution p.admonition-title,
div.danger p.admonition-title, div.error p.admonition-title,
div.warning p.admonition-title, .code .error {
  color: red ;
  font-weight: bold ;
  font-family: sans-serif }

/* Uncomment (and remove this text!) to get reduced vertical space in
   compound paragraphs.
div.compound .compound-first, div.compound .compound-middle {
  margin-bottom: 0.5em }

div.compound .compound-last, div.compound .compound-middle {
  margin-top: 0.5em }
*/

div.dedication {
  margin: 2em 5em ;
  text-align: center ;
  font-style: italic }

div.dedication p.topic-title {
  font-weight: bold ;
  font-style: normal }

div.figure {
  margin-left: 2em ;
  margin-right: 2em }

div.footer, div.header {
  clear: both;
  font-size: smaller }

div.line-block {
  display: block ;
  margin-top: 1em ;
  margin-bottom: 1em }

div.line-block div.line-block {
  margin-top: 0 ;
  margin-bottom: 0 ;
  margin-left: 1.5em }

div.sidebar {
  margin: 0 0 0.5em 1em ;
  border: medium outset ;
  padding: 1em ;
  background-color: #ffffee ;
  width: 40% ;
  float: right ;
  clear: right }

div.sidebar p.rubric {
  font-family: sans-serif ;
  font-size: medium }

div.system-messages {
  margin: 5em }

div.system-messages h1 {
  color: red }

div.system-message {
  border: medium outset ;
  padding: 1em }

div.system-message p.system-message-title {
  color: red ;
  font-weight: bold }

div.topic {
  margin: 2em }

h1.section-subtitle, h2.section-subtitle, h3.section-subtitle,
h4.section-subtitle, h5.section-subtitle, h6.section-subtitle {
  margin-top: 0.4em }

h1.title {
  text-align: center }

h2.subtitle {
  text-align: center }

hr.docutils {
  width: 75% }

img.align-left, .figure.align-left, object.align-left, table.align-left {
  clear: left ;
  float: left ;
  margin-right: 1em }

img.align-right, .figure.align-right, object.align-right, table.align-right {
  clear: right ;
  float: right ;
  margin-left: 1em }

img.align-center, .figure.align-center, object.align-center {
  display: block;
  margin-left: auto;
  margin-right: auto;
}

table.align-center {
  margin-left: auto;
  margin-right: auto;
}

.align-left {
  text-align: left }

.align-center {
  clear: both ;
  text-align: center }

.align-right {
  text-align: right }

/* reset inner alignment in figures */
div.align-right {
  text-align: inherit }

/* div.align-center * { */
/*   text-align: left } */

.align-top    {
  vertical-align: top }

.align-middle {
  vertical-align: middle }

.align-bottom {
  vertical-align: bottom }

ol.simple, ul.simple {
  margin-bottom: 1em }

ol.arabic {
  list-style: decimal }

ol.loweralpha {
  list-style: lower-alpha }

ol.upperalpha {
  list-style: upper-alpha }

ol.lowerroman {
  list-style: lower-roman }

ol.upperroman {
  list-style: upper-roman }

p.attribution {
  text-align: right ;
  margin-left: 50% }

p.caption {
  font-style: italic }

p.credits {
  font-style: italic ;
  font-size: smaller }

p.label {
  white-space: nowrap }

p.rubric {
  font-weight: bold ;
  font-size: larger ;
  color: maroon ;
  text-align: center }

p.sidebar-title {
  font-family: sans-serif ;
  font-weight: bold ;
  font-size: larger }

p.sidebar-subtitle {
  font-family: sans-serif ;
  font-weight: bold }

p.topic-title {
  font-weight: bold }

pre.address {
  margin-bottom: 0 ;
  margin-top: 0 ;
  font: inherit }

pre.literal-block, pre.doctest-block, pre.math, pre.code {
  margin-left: 2em ;
  margin-right: 2em }

pre.code .ln { color: grey; } /* line numbers */
pre.code, code { background-color: #eeeeee }
pre.code .comment, code .comment { color: #5C6576 }
pre.code .keyword, code .keyword { color: #3B0D06; font-weight: bold }
pre.code .literal.string, code .literal.string { color: #0C5404 }
pre.code .name.builtin, code .name.builtin { color: #352B84 }
pre.code .deleted, code .deleted { background-color: #DEB0A1}
pre.code .inserted, code .inserted { background-color: #A3D289}

span.classifier {
  font-family: sans-serif ;
  font-style: oblique }

span.classifier-delimiter {
  font-family: sans-serif ;
  font-weight: bold }

span.interpreted {
  font-family: sans-serif }

span.option {
  white-space: nowrap }

span.pre {
  white-space: pre }

span.problematic {
  color: red }

span.section-subtitle {
  /* font-size relative to parent (h1..h6 element) */
  font-size: 80% }

table.citation {
  border-left: solid 1px gray;
  margin-left: 1px }

table.docinfo {
  margin: 2em 4em }

table.docutils {
  margin-top: 0.5em ;
  margin-bottom: 0.5em }

table.footnote {
  border-left: solid 1px black;
  margin-left: 1px }

table.docutils td, table.docutils th,
table.docinfo td, table.docinfo th {
  padding-left: 0.5em ;
  padding-right: 0.5em ;
  vertical-align: top }

table.docutils th.field-name, table.docinfo th.docinfo-name {
  font-weight: bold ;
  text-align: left ;
  white-space: nowrap ;
  padding-left: 0 }

/* "booktabs" style (no vertical lines) */
table.docutils.booktabs {
  border: 0px;
  border-top: 2px solid;
  border-bottom: 2px solid;
  border-collapse: collapse;
}
table.docutils.booktabs * {
  border: 0px;
}
table.docutils.booktabs th {
  border-bottom: thin solid;
  text-align: left;
}

h1 tt.docutils, h2 tt.docutils, h3 tt.docutils,
h4 tt.docutils, h5 tt.docutils, h6 tt.docutils {
  font-size: 100% }

ul.auto-toc {
  list-style-type: none }

</style>

<style>
/*
:Author: Todd Miller
:Contact: jmiller@stsci.edu
:Copyright: This stylesheet has been placed in the public domain.

Stylesheet for use with Docutils.  [Optionally place a more
detailed description here.]
*/

@import url(html4css1.css);

/* Your customizations go here.  For example: */


h1 {
    color: #191970;
    font-family: sans-serif;
}

h2 {
    color: darkblue;
    font-family: sans-serif;
}

h3 {
    color: darkblue;
    font-style: italic;
    font-family: sans-serif;
}

h4 {
   color: darkgreen;
        text-decoration: underline;
   font-family: sans-serif;
}

p {
  color: #808080;
}

</style>

</head>
<body>
<div class="document">


<div class="section" id="overview">
<h1>Overview</h1>
<p>This note largely documents the design and syntax of CRDS certify .tpn
constraint definition files.   But as an overview,  CRDS certify performs
these forms of checks:</p>
<pre class="literal-block">
1. .tpn defined constraint checks unique to CRDS
2. spec defined unique table row checks, missing mode checks
3. fitsverify checks, recategorized as needed
4. astropy.io.fits, ASDF, JSON, YAML format checks
5. JWST data models open() checks
6. JWST data models scraped value checks
</pre>
<p>.tpn files are used by CRDS certify to define checks on reference file
header keywords and array properties.</p>
<p>For HST .tpn files define almost all CRDS checks (some table checks also exist)
and were incorporated verbatim from CDBS certify to simplify porting a moving
target.</p>
<p>For JWST, CRDS certify .tpn checks are used to extend and augment the checks
performed by the data models, e.g. adding the notion of &quot;required&quot; when
specified or implied, checking array dimensions, checking keyword
interrelationships, etc.  CRDS .tpn syntax was significantly extended from HST
to support additional forms and organizations of checks as well as the original
checks.</p>
</div>
<div class="section" id="tpn-file-organizations">
<h1>.tpn File Organizations</h1>
<p>For HST, .tpn files were written for every combination of &lt;instrument&gt;_&lt;type&gt;.</p>
<p>There are two forms of .tpn, one which constraints reference file properties
(.tpn) and one which constraints rmap properties (_ld.tpn).  The _ld.tpn files
originally constrained the expanded CDBS database matching parameter values.
While limiting the file structure to &lt;instrument&gt;_&lt;type&gt; combinations was
simple, there was also an extreme penalty for redundantly specified checks of
common constraints like PEDIGREE or USEAFTER.</p>
<p>For JWST, additional broader classes of .tpn are also defined and all
applicable forms are loaded for any given reference file:</p>
<pre class="literal-block">
all _ all .tpn                 (constraints on all instruments and types)
&lt;instrument&gt; _ all .tpn        (constraints on all types of one instrument)
all _ &lt;type&gt; .tpn              (constraints on one type of all instruments)
&lt;instrument&gt; _ &lt;type&gt; .tpn     (constraint on one instrument and type)
</pre>
<p>For JWST,  the additional file classes permit generalization of constraints
without added redundancy.   PEDIGREE can defined once in all_all,  etc.</p>
<div class="section" id="standard-tpn-directives">
<h2>Standard .tpn directives</h2>
<p>Typical constraint directives result in a CRDS TpnInfo() object being defined
in CRDS certify, which corresponds 1:1 to a CRDS Validator() object/subclass.
The TpnInfo() is a bundle of constraint information, a Validator() is a class
which checks the constraint defined by a TpnInfo.  Ultimately the outcome of
.tpn files is a list of TpnInfo() constraints to check, which are tuples of
properties, interpreted via appropriate Validator() subclassses.</p>
</div>
<div class="section" id="synthetic-tpn-directives">
<h2>Synthetic .tpn directives</h2>
<p>The CRDS certifier uses the JWST data models in two ways:</p>
<p>1. CRDS certify calls datamodels.open() on each reference to directly apply
data models checks.  This is very simple and fairly robust, but suffers from
the dependency of open() on the DATAMODL keyword which is used to specify the
model class of the reference file.  The model class implies the exact schema to
check.  If DATAMODL is not specified, open() won't validate specialized schema.</p>
<p>2. Second, CRDS loads the data models core schema and converts them into
synthetic TpnInfo() objects which don't appear in a .tpn file.  These synthetic
constraints are interpreted by CRDS normally to make that checking visible and
also to permit automatically promoting the constraints from &quot;optional&quot; (check
if present) to &quot;definintely required&quot; where keywords are needed for CRDS
matching.  The synthetic TpnInfo() objects generally scrape value enumerations
from the core schema for use in CRDS.</p>
</div>
</div>
<div class="section" id="file-directives">
<h1>File Directives</h1>
<p>.tpn files contain several forms of directives: include, replace, and
constraint.</p>
<div class="section" id="include-directive">
<h2>Include Directive</h2>
<p>The semantics of 'include' are roughly model'ed after the C pre-processor's
#include directives.</p>
<p>The include directive permits one .tpn file to include the text of another as
if the directive was replaced by the contents of the included file.  This
permits factoring out common constraints into a single file and using them
in multiple locations, e.g.:</p>
<pre class="literal-block">
include nir_sci_array.tpn
</pre>
<p>defines constraints on the SCI array for all NIR instruments except NIRSPEC.</p>
<p>For the sake of simplicity, the line of the directive should begin with
'include' (unquoted), a single space, and the name of the included .tpn file
(also unquoted).  Like many CRDS directives it is space delimited and consists
of exactly two words,  written on a single line.</p>
<p>An included file should also be located in the .tpn includes directory and
generally will not follow the JWST classes of include files (all_all, fgs_all,
etc.) or their naming conventions.</p>
</div>
<div class="section" id="replace-directive">
<h2>Replace Directive</h2>
<p>The replace directive causes CRDS to do substitutions on all subsequent lines
in the .tpn file, even lines included from other .tpn files.  The replace
directive consists of 3 words in the general form of:</p>
<pre class="literal-block">
replace &lt;original_pattern&gt; &lt;replacement&gt;
</pre>
<p>where an example directive is:</p>
<pre class="literal-block">
replace SCI COEFFS
</pre>
<p>which means that all subsequent instances of the pattern SCI in a particular
.tpn (or included .tpns) should be replaced by COEFFS.  In this case, it
effectively rewrites constraints on the SCI array as constraints on the COEFFS
array.</p>
<p>An important limitation of 'replace' to note is that it only applies within the
textual extent of on particular file class.   At this time,  it's not possible
to e.g. define a replacement in all_all and have it apply everywhere.</p>
</div>
<div class="section" id="constraint-directive">
<h2>Constraint Directive</h2>
<p>By far the most common directive is the constraint directive, which defines one
condition on a reference file and is of the form:</p>
<pre class="literal-block">
&lt;name&gt;  &lt;keytype&gt;  &lt;datatype&gt;  &lt;presence&gt;   &lt;value constraint&gt;
</pre>
<p>or sometimes with the values omitted:</p>
<pre class="literal-block">
&lt;name&gt;  &lt;keytype&gt;  &lt;datatype&gt;  &lt;presence&gt;
</pre>
<p>Before explaining each field in detail, a typical (but abbreviated) example
constraint taken from JWST is:</p>
<pre class="literal-block">
META.INSTRUMENT.PUPIL  H   C   O  CLEAR,CLEARP,F090W,F115W,F140M,F150W,F158M,\
                                   F162M,F164N,F200W,F323N,F405N,F466N
</pre>
<p>The columns of the constraint are interpreted as follows:</p>
<ol class="arabic simple">
<li>The first space delimited word defines the keyword / data model path: META.INSTRUMENT.PUPIL</li>
<li>The second word defines this as a (H)eader keyword constraint vs. e.g. (C)olumn</li>
<li>The third word defines this as a (C)haracter keyword value vs. e.g. (F)loat</li>
<li>The fourth word defines this as (O)ptional, it may be omitted.  Another
common value is (R)equired.  An expression may also be used in this slot to
define if/if-not the constraint should apply at all; additional semantic
refinements may also be added by wrapping helper functions.</li>
<li>The final &quot;word&quot; is a comma separated list of values.  Multiple lines may be
used by terminating each line with a backslash except the final line. In
some cases the value list is replaced by a Python expression which should
evaluate to True.    Literal numerical ranges may also be specified.</li>
</ol>
<div class="section" id="whitespace-in-constraint-fields">
<h3>Whitespace in Constraint Fields</h3>
<p>Since whitespace is used to delimit fields within a constraint, spaces /
whitespace MAY NOT appear within any single field, i.e. the value list,
presence expressions, constraint expressions, etc.  This can be slightly
awkward at times but the addition of extra parentheses to existing punctuation
is generally sufficient to write expressions containing no spaces.</p>
<p>For example, even expressions such as:</p>
<pre class="literal-block">
(&quot;IFU&quot; not in EXP_TYPE)
</pre>
<p>which contain instrinsic whitespace can often be rephrased in a workable way
as:</p>
<pre class="literal-block">
(not((&quot;IFU&quot;)in(EXP_TYPE)))
</pre>
<p>A limitation of this approach is that literal strings containing white space
are not permitted/straightforward in expressions.  In that area, writing
additional helper functions or custom validators might provide a way out.</p>
<p>While the idea of modernizing .tpn syntax is pretty obvious, the downsides of
switching to more readable file formats like JSON or YAML are a combination of:</p>
<pre class="literal-block">
* Up-front work
* Additional testing for multiple projects
* Constraints which become more verbose and less dense.
</pre>
<p>Since constraints are easier to read and consider en masse when they're
expressed in a dense format, not even readability is a complete slam dunk as a
motivation for modernizing formats.</p>
</div>
<div class="section" id="name-field">
<h3>&lt;Name&gt; Field</h3>
<p>The name field specifies the name of a header keyword, table column, array,
or expression constraint.</p>
<div class="section" id="header-keyword-names">
<h4>Header Keyword Names</h4>
<p>Header and table keyword names correspond roughly to FITS keywords or JWST CAL
data models paths flattened into a single string, e.g.:</p>
<pre class="literal-block">
 READPATT
 META.EXPOSURE.READPATT

Array Names
+++++++++++
</pre>
<p>Array names are specified as the bare HDU name in the &lt;name&gt; field, e.g. SCI.
These are referenced within expressions as &lt;name&gt;_ARRAY.  These are case
insensitive and specified in all capital letters, numbers, or underscores much
like FITS keywords.  They should begin with a letter and be valid program
identifiers.</p>
<p>There are two additional specification cases for array names:</p>
<ol class="arabic simple">
<li>FITS extensions can also named by number, e.g.  EXT1 or EXTENSION1 refers to
the data of HDU #1.  In constraint expressions these are referred to as
e.g. EXT1_ARRAY.  These can be discriminated from normal header keywords by
the keytype, which will be array vs. header.</li>
<li>FITS extensions can be named by (name, ver), in CRDS this is denoted as
&lt;name&gt;__&lt;ver&gt;, which corresponds to e.g. ('SCI', 1).  In constraint
expressions they are referred to as as &lt;name&gt;__&lt;ver&gt;_ARRAY,
e.g. SCI__1_ARRAY.  These can be differentiated from normal array extension
names by the double-underscore-digit convention,  an imperfect compromise.</li>
</ol>
</div>
<div class="section" id="expression-constraint-names">
<h4>Expression Constraint Names</h4>
<p>Expression constraint names describe the check performed by the value
expression, they do not describe any physical entity within the reference file.
Note that expression here refers to a keytype=X constraint and have no relation
to expressions used in the &lt;presence&gt; field described below.</p>
</div>
</div>
<div class="section" id="keytype-field">
<h3>&lt;Keytype&gt; Field</h3>
<p>The keytype field consists of one character corresponding to:</p>
<pre class="literal-block">
keytypes = {
   &quot;H&quot; : &quot;HEADER&quot;,
   &quot;C&quot; : &quot;COLUMN&quot;,
   &quot;G&quot; : &quot;GROUP&quot;,
   &quot;A&quot; : &quot;ARRAY_FORMAT&quot;,
   &quot;D&quot; : &quot;ARRAY_DATA&quot;,
   &quot;X&quot; : &quot;EXPRESSION&quot;,
}
</pre>
<div class="section" id="header-keywords-h">
<h4>Header Keywords (H)</h4>
<p>Header keyword names correspond to values taken from the union of all HDU
headers.</p>
<p>Almost all of the HST constraints taken from CDBS are enumerations applying to
a single FITS or GEIS keyword, e.g.  READPATT.</p>
<p>Many JWST constraints are written using the format independent (FITS, ASDF,
JSON...)  data model hiearchical path names munged for CRDS purposes into all
capital letters with periods replaced by underscores so that they can be
evaluated as a single keyword name rather than as nested objects.</p>
</div>
<div class="section" id="columns-c">
<h4>Columns (C)</h4>
<p>Column names generally apply to the name of a FITS table column and the
corresponding constraint applies only to the values of that single column in
isolation.</p>
</div>
<div class="section" id="array-format-a">
<h4>Array Format (A)</h4>
<p>Array format constraints apply to lightweight array properties taken from
FITS HDU data:</p>
<pre class="literal-block">
utils.Struct(
    SHAPE = hdu.data.shape,
    KIND = generic_class,
    DATA_TYPE = typespec,
    COLUMN_NAMES = column_names,
    EXTENSION = i,
    DATA = None,
)
</pre>
<p>Most notably, the array data itself is not available for constraint checking
but the lightweight properties are relatively fast and small to load.</p>
<p>Generally, array format and data keytypes have expression constraints rather
than value enumerations, ranges, etc.  Most commonly expressions limit the
array shape and type.</p>
<p>Array expressions can be written in terms of all arrays for which constraints
are defined.  So an ERR array constraint might also refer to SCI if it was
known to be loaded elsewhere.</p>
</div>
<div class="section" id="array-data-d">
<h4>Array Data (D)</h4>
<p>Array data checks are heavy weight and entail loading the actual reference data
so that constraints can be applied to it:</p>
<pre class="literal-block">
utils.Struct(
    SHAPE = hdu.data.shape,
    KIND = generic_class,
    DATA_TYPE = typespec,
    COLUMN_NAMES = column_names,
    EXTENSION = i,
    DATA = hdu.data      #  XXX the difference between 'A' and 'D' constraints!
)
</pre>
<p>Generally,  array format and data keytypes have expression constraints rather than
value enumerations, ranges, etc.  Most commonly expressions limit the array shape
and type.</p>
</div>
<div class="section" id="expressions-x">
<h4>Expressions (X)</h4>
<p>Expressions replace the typical value enumeration, range, etc. with a Python
expression written in terms of the reference file header and array properties.
While A and D array constraints are also generally written as as expressions,
in contrast, an X constraint loads no new array properties and includes no
arrays.  The value expression should be written in terms of header keywords
only.   Arrays are pre-loaded and remain available to all expressions for the
duration of a single reference file check.</p>
</div>
<div class="section" id="group-g">
<h4>Group (G)</h4>
<p>Not implemented but parsed for the sake of HST CDBS backward compatibility.</p>
</div>
</div>
<div class="section" id="datatype-field">
<h3>&lt;Datatype&gt; Field</h3>
<p>The datatype field conceptually corresponds to the type of a FITS keyword
defined in the reference file header or table.  Similar properties are imposed
on data models paths/keywords which may or may not correspond to a FITS
keyword.</p>
<p>The datatype is written as a single character with these translations:</p>
<pre class="literal-block">
datatypes = {
   &quot;C&quot; : &quot;CHARACTER&quot;,
   &quot;I&quot; : &quot;INTEGER&quot;,
   &quot;L&quot; : &quot;LOGICAL&quot;,
   &quot;R&quot; : &quot;REAL&quot;,           #  float32 value(s)
   &quot;D&quot; : &quot;DOUBLE&quot;,         #  float64 value(s)
   &quot;X&quot; : &quot;EXPRESSION&quot;,     #  constraint expression expected
}
</pre>
<p>The X datatype indicates that the constraint will be a boolean expression and
hence has no data type;  it is abstract,  referring to no particular keyword
or array by definition...  although frequently expressions are used to check
type.</p>
</div>
<div class="section" id="presence-field">
<h3>&lt;Presence&gt; Field</h3>
<p>The presence field determines the conditions under which a constraint applies
and what should happen when it is omitted:</p>
<pre class="literal-block">
presences = {
    &quot;E&quot; : &quot;EXCLUDED&quot;,
    &quot;R&quot; : &quot;REQUIRED&quot;,
    &quot;P&quot; : &quot;REQUIRED&quot;,
    &quot;W&quot; : &quot;WARN&quot;,
    &quot;O&quot; : &quot;OPTIONAL&quot;,
    &quot;F&quot; : &quot;IF_FULL_FRAME&quot;,
    &quot;S&quot; : &quot;IF_SUBARRAY&quot;,
    &quot;A&quot; : &quot;ANY_SUBARRAY&quot;
}
</pre>
<div class="section" id="simple-presence-values">
<h4>Simple Presence Values</h4>
<p>Simple presence values are specified as a single character which correspond to
these classifications:</p>
<p><em>REQUIRED</em> or True results in an error if the keyword is not present in the file
header or tables or is UNDEFINED or the constraint is not satisfied.</p>
<p><em>False</em> means a constraint does not apply.</p>
<p><em>WARN</em> results in a warning if the keyword is not present or is UNDEFINED.</p>
<p><em>OPTIONAL</em> indicates that a constraint should be satisfied if the keyword is
present and not UNDEFINED but is not an error when omitted.</p>
<p><em>IF_FULL_FRAME</em> means that the constraint only applies when SUBARRAY keywords are
defined (SUBARRAY,SUBSTRT1,SUBSTRT2,SUBSIZE1,SUBSIZE2) and SUBARRAY describes a
full frame (FULL,GENERIC,N/A,ANY,*).</p>
<p><em>IF_SUBARRAY</em> means that the constraint only applies when SUBARRAY keywords are
defined and SUBARRAY does not describe a full frame.</p>
<p><em>ANY_SUBARRAY</em> means that the constraint only applies when SUBARRAY keywords are
defined.</p>
<p><em>EXCLUDED</em> means that a keyword should not be specified and was supplied for
backwards compatibility with HST CDBS and is generally unused.</p>
<p>For HST, every instrument and type specified the presence requirement for every
keyword.  This resulted in value enumerations repeated over and over throughout
the .tpn files.</p>
<p>For JWST, CRDS support specifying keywords as optional...  with one twist: if
an optional keyword is used by an rmap to perform matching (appears in the
'parkey' header field), then every optional constraint on that keyword for that
particular reftype becomes required.</p>
<p>This permits constraints to be specified once as optional at a relatively
global level for easier maintenance, but then become &quot;required&quot; if a particular
reftype uses the keyword directly within CRDS for matching.  (This is a
reflection of the &quot;prime directive&quot; of the CRDS certifier: while general checks
can be implemented, the most crucial aspect of CRDS checking is to ensure that
files work within CRDS.  Although CRDS does strive to implement additional
checks, the only real measure that references will work with the CAL code is
running calibrations.)</p>
<p>For even more control, or for keywords not used by CRDS matching, additional
constraints can be defined in more specialized .tpn's.</p>
</div>
<div class="section" id="presence-expressions-and-helpers">
<h4>Presence Expressions and Helpers</h4>
<p>A Python expression can be specified to define when a constraint does or
doesn't apply based on keyword values.</p>
<p>The expression should begin with ( and end with ) and should contain no spaces.
(Sometimes extra parens are required to break up the expression into words
using punctuation instead of spaces.)</p>
<p>An example of a presence expression is:</p>
<pre class="literal-block">
(EXP_TYPE!='FGS_ID-STACK')
</pre>
<p>which means that the constraint only applies when EXP_TYPE is not FGS_ID-STACK.</p>
<p>Keyword names used in presence expressions follow the usual rules and must be
valid Python identifiers in all caps.  Periods from data model paths are
replaced by underscores to make the paths into simple identifiers suitable for
Python's eval().</p>
<p>Presence helpers have been defined to convert the boolean result of a presence
expression into a simple presence value.  This enables conditional optional
keywords, conditional warnings, conditional subarray expressions, etc:</p>
<pre class="literal-block">
optional(expr)     --&gt;   False or 'O'
full_frame(expr)   --&gt;   False or 'F'
subarray(expr)     --&gt;   False or 'S'
any_subarray(expr) --&gt;   False or 'A'
required(expr)     --&gt;   False or 'R'
warn(expr)         --&gt;   False or 'W'
</pre>
<p>For example, an expression further refined by the full_frame() helper:</p>
<pre class="literal-block">
(full_frame(EXP_TYPE!='FGS_ID-STACK'))
</pre>
<p>means that fundamentally, it only implies when EXP_TYPE is not FGS_ID-STACK,
but in addition,  it only applies when SUBARRAY keywords are defined and the
SUBARRAY is some form of full frame, e.g.FULL or GENERIC.  In effect,  the
helper arranges things so that the presence field is 'F' if the wrapped
expression is satisfied.</p>
<p>Note that an expression return value of False indicates a constraint does not
apply at all.  An expression return value of True indicates the constraint is
REQUIRED.</p>
<p>Helper functions in .tpn files are distinguished by being written in all lower
case; this prevents collisions with keyword, column, or array names which are
always written in upper case.</p>
</div>
</div>
<div class="section" id="values">
<h3>&lt;Values&gt;</h3>
<p>The &lt;values&gt; field of each constraint can define a number of things, including
enumerations of literal values:</p>
<pre class="literal-block">
GUIDER1,GUIDER2
</pre>
<p>numerical ranges:</p>
<pre class="literal-block">
1:10
</pre>
<p>constraint expressions:</p>
<blockquote>
()</blockquote>
<p>custom validator identifiers:</p>
<pre class="literal-block">
&amp;PEDIGREE
</pre>
<p>or nothing at all.</p>
<div class="section" id="enumerations">
<h4>Enumerations</h4>
<p>Value enumerations list the possible literal values that can be assigned to
a keyword, e.g.:</p>
<pre class="literal-block">
FGS,NIRCAM,NIRISS,NIRSPEC,MIRI,SYSTEM
</pre>
</div>
<div class="section" id="ranges">
<h4>Ranges</h4>
<p>Ranges specify inclusive numerical ranges which keyword values must lie within,
e.g.:</p>
<pre class="literal-block">
1.0:10.0
</pre>
<p>means the value should be within 1 and 10 inclusive.  An equivalent expression
constraint would be:</p>
<pre class="literal-block">
(1.0&lt;=KEYWORD&lt;=10.0)
</pre>
<p>where KEYWORD is the name of the constrained keyword.</p>
</div>
<div class="section" id="custom-constraint-validators">
<h4>Custom Constraint Validators</h4>
<p>Custom constraint handlers define new classes of validators and are always
specified by a value / validator name beginning with &amp;, e.g.:</p>
<pre class="literal-block">
META.USEAFTER   H   C   R               &amp;JWSTDATE
</pre>
<p>where validator values have meanings like:</p>
<pre class="literal-block">
&amp;PEDIGREE  -- implements algorithm to check various PEDIGREE value forms
&amp;USEAFTER  -- implements HST USEAFTER date/time format checking
&amp;JWSTDATE  -- implements JWST date/time format checking,  e.g. JWST USEAFTER
</pre>
<p>Custom constraint validators can perform arbitrary processing to validate a
single keyword value, i.e. specify precise date formats, etc.  Custom
constraint validators are defined in the crds.certify.validators module with
classes named like e.g.  PedigreeValidator, UseafterValidator,
JwstdateValidator.</p>
</div>
<div class="section" id="expressions-constraints">
<h4>Expressions Constraints</h4>
<p>Unlike presence expressions which define when a constraint should or should not
be applied, expressions constraints define the condition which should be
satisfied when the constraint is applicable.</p>
<p>Someone might briefly wonder if both presence and constraint value expressions
are needed.  The answer is &quot;yes&quot; because a negative result of a value
expression is limited to &quot;constraint failed&quot; while a negative result for the
presence expression is limited to &quot;do not evaluate&quot;,  so the concerns truly
are separate and two expressions are needed.</p>
<p>Constraint expressions always begin with '(' and end with ')' and should
contain no spaces.</p>
<p>An example expression constraint is:</p>
<pre class="literal-block">
(1&lt;=META_SUBARRAY_XSTART+META_SUBARRAY_XSIZE-1&lt;=2048)
</pre>
<p>which asserts that XSTART + XSIZE - 1 should fall within the boundaries of
the detector's 2048 X-dimension.</p>
<p>When specified within CRDS .tpn files, JWST CAL data models paths (ie. keyword
names) are flattened to simple strings that resemble FITS keywords in all upper
case:</p>
<blockquote>
meta.subarray.xstart --&gt;  META.SUBARRAY.XSTART</blockquote>
<p>Within expressions,  the periods are replaced with underscores:</p>
<blockquote>
META.SUBARRAY.XSTART --&gt;  META_SUBARRAY_XSIZE</blockquote>
<p>so that when the name is eval()'ed it is a simple Python identifier instead of
a e.g. three nested objects.</p>
<p>Array identifiers appear in expression constraints as e.g. SCI_ARRAY to refer
to the SCI HDU properties.  In this case SCI_ARRAY is a true utils.Struct()
object so it refers to Struct() properties within the eval() expression using
normal Python object attribute access, e.g. SCI_ARRAY.SHAPE not
SCI_ARRAY_SHAPE.</p>
<div class="section" id="table-expression-helpers">
<h5>Table Expression Helpers</h5>
<p>Expression helper functions were added to check basic table properties based
on the contents of HDUS.   To some degree these are redundant to the HST &quot;C&quot;
column style constraints...  but have the advantage that they operate directly
on HDU array properties and type information.  In contrast,  the &quot;C&quot; column
constraints followed HST practices relying more on value string formatting,
e.g. &quot;if it looks like a FLOAT,  it is a FLOAT.&quot;  In practice,  file developers
actually do make the error of adding FLOAT repr()'s to references instead of
actual FLOAT values so this minor extension was added to enable checking that.</p>
<p>Some of the table helpers:</p>
<pre class="literal-block">
(is_table(xxx_ARRAY))
(is_image(xxx_ARRAY))
(has_columns(DQ_DEF_ARRAY,['BIT','VALUE','NAME','DESCRIPTION']))
(has_column_type(DQ_DEF_ARRAY,'BIT','INT'))
</pre>
</div>
</div>
</div>
<div class="section" id="empty-value-lists">
<h3>Empty Value Lists</h3>
<p>The value list can be empty, in which case the constraint is limited to
checking presence and type.</p>
</div>
</div>
</div>
<div class="section" id="unique-row-table-checks">
<h1>Unique Row Table Checks</h1>
<p>CRDS has an HST requirement to attempt to detect missing table modes.  This
is done by specifying table columns which should identify unique rows,  and
then comparing the unique rows of and old and new table to see if any unique
rows are dropped.   The same generic capability can also be used by JWST.</p>
<p>Because the table row checks are crude approximations, the net result is
generally one of two kinds of warnings.  First, a table may define more than
once instance of a row which should be uniquely identified; these are referred
to in a warning as &quot;duplicate&quot; rows.  Second, the new version of a table may
drop unique rows found in the original version; this is reported loosely as one
or more missing &quot;modes&quot;.</p>
<p>Unique rows are defined by combinations of column parameters.  The parameter
names used to select unique rows are defined in the &quot;spec&quot; file of each
reference type as needed in a unique_rows header field,  e.g.:</p>
<pre class="literal-block">
miri_cubepar.rmap:    'unique_rowkeys' : ('GRATING', 'FILTER'),
</pre>
<p>The spec files are located in the &quot;specs&quot; directory of each project directory,
e.g. crds/jwst/specs/miri_cubepar.rmap.  Spec files also define other static
reference type properties like short and long form names, etc.  To speed
loading on slow file systems,  specs for all instruments and types are combined
into a single combined_specs.json file for each project.</p>
<p>Because one reference may define more than one table, unique row names are only
used in the row selection combination if they're present in a particular table.
Independent .tpn checks can verfy that all required columns are present.</p>
<p>In the above example, if one table defined unique rows by GRATING, and a second
table defined unique rows by FILTER, CRDS would correctly support both table
checks.  In a different situation, unique table rows might be defined by
combinations of both FILTER and GRATING.   This dicey interpretation of unique
rows turns out to be good enough in practice,  it's relatively uncommon to
check multiple tables in one reference.</p>
</div>
<div class="section" id="debugging-certify-updates">
<h1>Debugging Certify Updates</h1>
<p>When run without --verbose, CRDS certify is relatively quiet about what it is
checking unless checks fail.  (A current exception which may change is the
regurgitation of the complete fitsverify output.  But most .tpn checks are
silent unless --verbose is set or they fail.)</p>
<p>Verifying changes to CRDS certify .tpn files can generally done by running
certify over some context, imap, or rmap in <em>--deep</em> mode which will attempt to
certify each reference file and/or sub-mapping.  Further, turning on the debug
messages with --verbose or --verbosity=60 or 70 or.. will generate output on
what CRDS is checking, how, and why / why not.</p>
<p>An example of running CRDS this way would be:</p>
<pre class="literal-block">
$ export CRDS_SERVER_URL=https://jwst-crds.stsci.edu
$ export CRDS_PATH=/grp/crds/cache
$ crds certify jwst-nirspec-superbias-edit --deep --dump-unique-errors --verbose --dump-provenance
</pre>
<p>The output, which is copious, is relatively self-explanatory.  Typically one
greps through it for output from the constraint being added or modified.</p>
<p>For extensive changes to certify,  it can be useful to run it on all the
active reference files like this:</p>
<pre class="literal-block">
$ export CRDS_SERVER_URL=https://jwst-crds.stsci.edu
$ export CRDS_PATH=/grp/crds/cache
$ crds certify  jwst-edit --deep --dump-unique-errors --verbose --dump-provenance
</pre>
<p>where the symbolic context name 'jwst-edit' is interpreted to something more
literal like 'jwst_0442.pmap'.  Likewise, exhaustive testing may require
running certify on 'hst-edit' as well after setting:</p>
<pre class="literal-block">
$ export CRDS_SERVER_URL=https://hst-crds.stsci.edu
</pre>
</div>
<div class="section" id="other-notes">
<h1>Other Notes</h1>
<div class="section" id="irs2-readouts-and-2048x3200">
<h2>#1 - IRS2 readouts and 2048x3200</h2>
<p>NIRSpec IRS2 readouts produce 3200 pixels in one image dimension. In the native
detector readout orientation it's nx=3200, ny=2048 (i.e. it's a horizontal
rectangle). But all science data and all reference data in CRDS always need to
be in DMS (science) orientation, which for NIRSpec means the x/y axes get
swapped, so that means IRS2 images have nx=2048, ny=3200 (i.e. a vertical
rectangle). Taking a quick look at one of the NIRSpec MASK ref files in CRDS
for IRS2 mode, it correctly shows that the image has dimensions of
2048x3200. So that's the correct orientation you're looking for. If anyone ever
delivers a NIRSpec ref file to CRDS that has dimensions 3200x2048, it's wrong
(it's still in native detector orientation) and needs to be rejected.</p>
<p>The complicating factor in all of this is that a conscious decision was made to
still have the SUBSTRTn keywords (datamodel meta.subarray.[xy]size) retain
their original values of 2048, rather than 3200, because the extra pixels in
the image do not correspond to real pixels on the detector (they're virtual
values inserted into the image). So the detector was still commanded to readout
2048x2048 pixels, hence the decision to make the size keywords still say
2048x2048. Even though ny=3200 in the actual image. So any comparison of
subarray size keyword values against the actual image size needs to allow for
this (i.e. it's OK to have meta.subarray.ysize=2048 when data.shape[-2] =
3200), as long as READPATT has the string &quot;IRS2&quot; somewhere in it.</p>
</div>
<div class="section" id="substrt-1-2-reference-pixels">
<h2>#2 - SUBSTRT 1/2 &amp; reference pixels</h2>
<p>For the JWST detectors all reference pixels are physical pixels that are
counted as part of the detector dimensions (unlike virtual overscan regions
in CCD's). So the 2048x2048 detector dimensions of the near-IR detectors
already includes the reference pixels and the MIRI detectors are always
referenced in the full 1032x1024 space that includes their reference
pixels. The SUBSTRTn and SUBSIZEn values also always include the reference
pixels (i.e. SUBSTRT1 = 1 means the subarray is starting on the first
reference pixel. The first &quot;live&quot; pixel is at SUBSTRT1 = 5.) So for MIRI
full-frame readouts SUBSIZE1 = 1032, not 1024 (the same as NAXIS1).</p>
<p>The only exception to this is the NIRSpec IRS2 readout mode that includes
many more columns of reference pixels interspersed within the live pixels,
resulting in total image dimensions that are greater than 2048 (at least
along the y image axis). So this is the only case where SUBSIZEn != NAXISn,
because NAXIS2 2048, while a decision was made to still set SUBSIZE2 = 2048.</p>
</div>
<div class="section" id="dark-array-ndim">
<h2># 3 - DARK array NDIM</h2>
<p>Comments about array dimensions and array shape equivalence:</p>
<p>DARK: non-MIRI: SCI=ERR=3D, DQ=2D; MIRI: SCI=ERR=DQ=4D</p>
<p>LINEARITY: COEFFS=3D, DQ=2D</p>
</div>
<div class="section" id="nirspec-dark-no-reference-pixels">
<h2># 4 - NIRSPEC DARK no reference pixels</h2>
<p>For NIRSpec data, the DARK step is run (in calwebb_detector1.py) after
refpix, so the image at that point will be 2048 x 2048, and the dark file will
have shape (N, 2048, 2048), where N has to do with the number of groups.  So it
is correct that the darks will be 2048x2048.</p>
<p>Similarly for READNOISE.</p>
</div>
<div class="section" id="nirspec-subarray-gain-2-striping">
<h2># 5 - NIRSPEC SUBARRAY GAIN=2 STRIPING</h2>
<p>If memory serves, in a conversation we all had with NIRSpec folks about a year
ago, they need to deliver some subarray ref files with SUBARRAY='GENERIC',
because the exact placement of the subarray varies from exposure to exposure
and is tied to the use of different gratings (different gratings result in
spectra being located in slightly different places on the detector and they
change the subarray location to match). So for example the &quot;mystery stripe&quot;
2048x256 subarray is probably used for fixed-slit exposures, where the 256 is
large enough to cover all the slits. Science exposures taken using a subarray
for a single slit (which is smaller yet) will use that 2048x256 reference file
and extract (on the fly) the subarray that matches the smaller science
subarray, matching both the location and size of the subarray used in the
science exposure. So that's why SUBARRAY has to be set to 'GENERIC' in those
ref files, so that CRDS knows to select it when a science exposure uses some
other specific subarray like &quot;SUBS200A1&quot; or &quot;SUBS400A1&quot; and let the cal
pipeline do the on-the-fly extraction thing, like it also does when full-frame
ref files use SUBARRAY='GENERIC'.</p>
<p>The reason they can't just use a full-frame ref file with SUBARRAY='GENERIC'
for these, is because NIRSpec subarrays are readout using a different gain than
full-frame, so they have to use subarray-specific reference files (because the
actual pixel values in the images are different than for full-frame).</p>
</div>
<div class="section" id="gain-sci-hdu-and-gainfact">
<h2># 6 - GAIN SCI HDU and GAINFACT</h2>
<p>The GainModel schema specifies a single FITS HDU with EXTNAME='SCI'. The jump
and ramp_fit steps, which use the gain ref file, both load it into a GainModel
data model, hence if there isn't a SCI extension present I would assume the
load would fail. Therefore the SCI label should be mandatory.</p>
<p>The GAINFACT keyword is only used (and hence required) for NIRSpec gain ref
files that are subarray (like jwst_nirspec_gain_0016.fits and
jwst_nirspec_gain_0017.fits). So GAINFACT is only needed when the ref data have
dimensions less than 2048x2048.</p>
</div>
<div class="section" id="area-miri-sci-dimensions">
<h2># 7 - AREA MIRI SCI dimensions</h2>
<p>Huh, never noticed this before, which is due to the fact that all we do with
the imaging-mode AREA reference files is attach the data array to an extra
extension in the science product and that's it - we don't actually use it or
apply it anywhere. It's information only, for possible use by the user while
doing analysis. The reference pixels don't get stripped off until level-3
processing, which combines multiple images. Level-2 products, which is the
stage where a user might need to use the AREA data, still have the reference
pixels in the image. So theoretically I guess the AREA array should be the
original 1032x1024 size that includes the reference pixels, just for ease in
applying it to the science image, which will still be 1032x1024 at that point.</p>
<p>AREA ref files for the imaging mode of other instruments, like NIRCam, are the
full 2048x2048 size, which means they contain reference pixels. Hence for
consistency we should request that the MIRI IDT deliver theirs the same way.</p>
</div>
</div>
</div>
</body>
</html>

